{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import sklearn.feature_extraction as fe\n",
    "import pickle\n",
    "from gensim.models import KeyedVectors\n",
    "from scipy.sparse import hstack, vstack, csr_matrix, coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path_to_data = os.getcwd() + \"/data/\"\n",
    "path_to_w2v_models = \"/Users/Nurislam/Documents/w2v_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(971157, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path_to_data + \"data.tsv\", sep=\"\\t\")\n",
    "print (df.shape)\n",
    "df = df.fillna(\"\")\n",
    "#df_without_nan = df.dropna()\n",
    "#print (df_without_nan.shape)\n",
    "#print (df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = df[df.columns[1]].str.lower()\n",
    "labels = df[df.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_texts():\n",
    "    with open(path_to_data + \"texts\", \"w\") as f:\n",
    "        for text in texts:\n",
    "            f.write(text + \"\\n\")\n",
    "            \n",
    "write_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stemming lemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 42.6 s, total: 2min 10s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "# doc2vec\n",
    "# char2vec\n",
    "\n",
    "class SentencesIterator(object):\n",
    "    def __init__(self, corpus_dir, filenames):\n",
    "        self.corpus_dir = corpus_dir\n",
    "        self.filenames = filenames\n",
    "\n",
    "    def __iter__(self):\n",
    "        for f in self.filenames:\n",
    "            for line in open(self.corpus_dir + f):\n",
    "                yield line.split()\n",
    "                \n",
    "def create_w2v_own():\n",
    "    sentences = SentencesIterator(path_to_data, [\"texts\"])\n",
    "\n",
    "    # update parametres\n",
    "    model = gensim.models.Word2Vec(sentences, size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "    model.wv.save_word2vec_format(path_to_w2v_models + \"/own_w2v_model\", binary=True)\n",
    "    \n",
    "%time create_w2v_own()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 728 ms, total: 14.1 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "def create_vectorizer(texts, use_if_idf = False):\n",
    "    if use_if_idf:\n",
    "        # изменить параметры\n",
    "        v = fe.text.TfidfVectorizer()\n",
    "    else:\n",
    "        v = fe.text.CountVectorizer()\n",
    "\n",
    "    v.fit_transform(texts)\n",
    "\n",
    "    with open(path_to_data + \"vectorizer\", \"wb\") as f:\n",
    "        pickle.dump(v, f)\n",
    "        \n",
    "%time create_vectorizer(texts, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ускорить вычисления\n",
    "def get_vectors_by_texts_w2v_model(w2v, texts):\n",
    "    arr = []\n",
    "    \n",
    "    num = 0\n",
    "\n",
    "    # если отсутствует принимаем за zero или не учитываем?\n",
    "    for i in texts:\n",
    "        words = i.split(\" \")\n",
    "        words_exist = []\n",
    "        for j in words:\n",
    "            if j in w2v.vocab:\n",
    "                words_exist.append(j)\n",
    "                \n",
    "        if len(words_exist) == 0:\n",
    "            arr.append(np.zeros(w2v.vector_size))\n",
    "        else:        \n",
    "            vec = w2v[words_exist]\n",
    "            arr.append(np.mean(vec, axis=0))\n",
    "        if num % 100000 == 0:\n",
    "            print (\"chunk \" + str(num))\n",
    "            \n",
    "        num += 1\n",
    "        \n",
    "    return np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "CPU times: user 27.1 s, sys: 5 s, total: 32.1 s\n",
      "Wall time: 34.9 s\n"
     ]
    }
   ],
   "source": [
    "# подбор моделей\n",
    "exist_big_models = [\"ruscorpora_russe.model.bin\", #1 gb,\n",
    "                    \"ruwikiruscorpora_rusvectores2.bin\", # 400,\n",
    "                    \"ruscorpora_1_600_2.bin\", # 400,\n",
    "                    \"ruscorpora_1_300_10.bin\"] # 200 NOUN, ADJ\n",
    "    \n",
    "w2v_big = KeyedVectors.load_word2vec_format(path_to_w2v_models + exist_big_models[0], binary=True)\n",
    "\n",
    "%time vec_w2v_1 = get_vectors_by_texts_w2v_model(w2v_big, texts)\n",
    "\n",
    "%time np.savetxt(path_to_data + \"vec_w2v_1\", vec_w2v_1, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "CPU times: user 30 s, sys: 1.16 s, total: 31.2 s\n",
      "Wall time: 31.3 s\n"
     ]
    }
   ],
   "source": [
    "w2v_own = KeyedVectors.load_word2vec_format(path_to_w2v_models + \"/own_w2v_model\", binary=True)\n",
    "\n",
    "%time vec_w2v_2 = get_vectors_by_texts_w2v_model(w2v_own, texts)\n",
    "\n",
    "%time np.savetxt(path_to_data + \"vec_w2v_2\", vec_w2v_2, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(path_to_data + \"vectorizer\", \"rb\"))\n",
    "\n",
    "vec_vectorizer = vectorizer.transform(texts)\n",
    "\n",
    "with open(path_to_data + \"vec_vectorizer\", \"wb\") as f:\n",
    "    pickle.dump(vec_vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load first\n",
      "to csr\n",
      "load second\n",
      "to csr\n"
     ]
    }
   ],
   "source": [
    "features = None\n",
    "    \n",
    "print (\"load first\")\n",
    "with open(path_to_data + \"vec_w2v_1\", \"rb\") as f:\n",
    "    vec_w2v_1 = np.loadtxt(path_to_data + \"vec_w2v_1\", delimiter=',')\n",
    "print (\"to csr\")\n",
    "vec_w2v_1 = csr_matrix(vec_w2v_1)\n",
    "        \n",
    "print (\"load second\")\n",
    "with open(path_to_data + \"vec_w2v_2\", \"rb\") as f:\n",
    "    vec_w2v_2 = np.loadtxt(path_to_data + \"vec_w2v_2\", delimiter=',')\n",
    "print (\"to csr\")\n",
    "vec_w2v_2 = csr_matrix(vec_w2v_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load vectorizer\n",
      "start hstack1\n",
      "(971157, 400)\n",
      "start hstack 2\n",
      "(971157, 332388)\n"
     ]
    }
   ],
   "source": [
    "print (\"load vectorizer\")\n",
    "with open(path_to_data + \"vec_vectorizer\", \"rb\") as f:\n",
    "    vec_vectorizer = pickle.load(f)\n",
    "    \n",
    "print (\"start hstack1\")\n",
    "features = hstack((vec_w2v_1, vec_w2v_2))\n",
    "print (features.shape)\n",
    "print (\"start hstack 2\")\n",
    "features = hstack((features, vec_vectorizer))\n",
    "print (features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f3d36d06db72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time np.savetxt(path_to_data + \"features_full\", features, delimiter=\\',\\')'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipython-5.0.0.dev0-py3.5.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2162\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipython-5.0.0.dev0-py3.5.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2083\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2085\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipython-5.0.0.dev0-py3.5.egg/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipython-5.0.0.dev0-py3.5.egg/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m                     \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m                     raise TypeError(\"Mismatch between array dtype ('%s') and \"\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "%time np.savetxt(path_to_data + \"features_full\", features, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_perceptron_plain(X, y, model_id, epochs_main_neural, batch_size_main_neural):\n",
    "    X = csr_matrix(X)\n",
    "    y_train_new = []\n",
    "\n",
    "    num_labels = max(y)+1 # исправить\n",
    "    num_input = X[0].shape[1]\n",
    "\n",
    "    for i in y:\n",
    "        y_train_new.append(np.array([i]))\n",
    "\n",
    "    y_train_new = np.array(y_train_new)\n",
    "\n",
    "    one_hot_labels = keras.utils.to_categorical(y_train_new, num_classes=num_labels)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    model = Sequential()\n",
    "    # среднее между размером входа и размером выхода\n",
    "    model.add(Dense((num_input + num_labels) / 2, activation='sigmoid', input_dim=num_input))\n",
    "\n",
    "    # 17 - change\n",
    "    model.add(Dense(num_labels, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[metrics.mae, metrics.categorical_accuracy])\n",
    "\n",
    "    model.fit(X.todense(), one_hot_labels, epochs=epochs_main_neural, batch_size=batch_size_main_neural)\n",
    "\n",
    "    #PFTExtractingFs(model_id).save_keras_perceptron(model, \"neural\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras_perceptron_plain(vec_vectorizer, labels, 30, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}